{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abe65aa",
   "metadata": {},
   "source": [
    "## The Logistics Commander (CoT & ToT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b33441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.prompts import render\n",
    "from utils.llm_client import LLMClient\n",
    "from utils.logging_utils import log_llm_call\n",
    "from utils.router import pick_model, should_use_reasoning_model\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e85b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1  | 08:00 AM| Gampaha | 4      | 20-40  | Water     | \"Thirsty but safe on roof. Water level stable.\"',\n",
       " '2  | 08:15 AM| Ja-Ela  | 1      | 75     | Insulin   | \"Diabetic, missed dose yesterday. Feeling faint.\"',\n",
       " '3  | 08:20 AM| Ragama  | 2      | 10, 35 | Rescue    | \"Water approaching neck level. Child is crying.\"']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../data/incidents.txt\"\n",
    "\n",
    "# Read file as raw text\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# First line is header\n",
    "header = lines[0]\n",
    "rows = lines[1:]\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9d08ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'time': '08:00 AM',\n",
       "  'area': 'Gampaha',\n",
       "  'people': 4,\n",
       "  'ages': '20-40',\n",
       "  'main_need': 'Water',\n",
       "  'message': 'Thirsty but safe on roof. Water level stable.'},\n",
       " {'id': 2,\n",
       "  'time': '08:15 AM',\n",
       "  'area': 'Ja-Ela',\n",
       "  'people': 1,\n",
       "  'ages': '75',\n",
       "  'main_need': 'Insulin',\n",
       "  'message': 'Diabetic, missed dose yesterday. Feeling faint.'},\n",
       " {'id': 3,\n",
       "  'time': '08:20 AM',\n",
       "  'area': 'Ragama',\n",
       "  'people': 2,\n",
       "  'ages': '10, 35',\n",
       "  'main_need': 'Rescue',\n",
       "  'message': 'Water approaching neck level. Child is crying.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incidents = []\n",
    "\n",
    "for row in rows:\n",
    "    parts = [p.strip() for p in row.split(\"|\")]\n",
    "\n",
    "    incident = {\n",
    "        \"id\": int(parts[0]),\n",
    "        \"time\": parts[1],\n",
    "        \"area\": parts[2],\n",
    "        \"people\": int(parts[3]),\n",
    "        \"ages\": parts[4],\n",
    "        \"main_need\": parts[5],\n",
    "        \"message\": parts[6].strip('\"')\n",
    "    }\n",
    "\n",
    "    incidents.append(incident)\n",
    "\n",
    "incidents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318d3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>area</th>\n",
       "      <th>people</th>\n",
       "      <th>ages</th>\n",
       "      <th>main_need</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>08:00 AM</td>\n",
       "      <td>Gampaha</td>\n",
       "      <td>4</td>\n",
       "      <td>20-40</td>\n",
       "      <td>Water</td>\n",
       "      <td>Thirsty but safe on roof. Water level stable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>08:15 AM</td>\n",
       "      <td>Ja-Ela</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>Diabetic, missed dose yesterday. Feeling faint.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>08:20 AM</td>\n",
       "      <td>Ragama</td>\n",
       "      <td>2</td>\n",
       "      <td>10, 35</td>\n",
       "      <td>Rescue</td>\n",
       "      <td>Water approaching neck level. Child is crying.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time     area  people    ages main_need  \\\n",
       "0   1  08:00 AM  Gampaha       4   20-40     Water   \n",
       "1   2  08:15 AM   Ja-Ela       1      75   Insulin   \n",
       "2   3  08:20 AM   Ragama       2  10, 35    Rescue   \n",
       "\n",
       "                                           message  \n",
       "0    Thirsty but safe on roof. Water level stable.  \n",
       "1  Diabetic, missed dose yesterday. Feeling faint.  \n",
       "2   Water approaching neck level. Child is crying.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_incidents = pd.DataFrame(incidents)\n",
    "df_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a64b645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>area</th>\n",
       "      <th>people</th>\n",
       "      <th>ages</th>\n",
       "      <th>main_need</th>\n",
       "      <th>message</th>\n",
       "      <th>min_age</th>\n",
       "      <th>max_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>08:00 AM</td>\n",
       "      <td>Gampaha</td>\n",
       "      <td>4</td>\n",
       "      <td>20-40</td>\n",
       "      <td>Water</td>\n",
       "      <td>Thirsty but safe on roof. Water level stable.</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>08:15 AM</td>\n",
       "      <td>Ja-Ela</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>Insulin</td>\n",
       "      <td>Diabetic, missed dose yesterday. Feeling faint.</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>08:20 AM</td>\n",
       "      <td>Ragama</td>\n",
       "      <td>2</td>\n",
       "      <td>10, 35</td>\n",
       "      <td>Rescue</td>\n",
       "      <td>Water approaching neck level. Child is crying.</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      time     area  people    ages main_need  \\\n",
       "0   1  08:00 AM  Gampaha       4   20-40     Water   \n",
       "1   2  08:15 AM   Ja-Ela       1      75   Insulin   \n",
       "2   3  08:20 AM   Ragama       2  10, 35    Rescue   \n",
       "\n",
       "                                           message  min_age  max_age  \n",
       "0    Thirsty but safe on roof. Water level stable.       20       40  \n",
       "1  Diabetic, missed dose yesterday. Feeling faint.       75       75  \n",
       "2   Water approaching neck level. Child is crying.       10       35  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_ages(age_str):\n",
    "    nums = [int(x) for x in age_str.replace(\"-\", \",\").split(\",\")]\n",
    "    return min(nums), max(nums)\n",
    "\n",
    "df_incidents[[\"min_age\", \"max_age\"]] = df_incidents[\"ages\"].apply(\n",
    "    lambda x: pd.Series(parse_ages(x))\n",
    ")\n",
    "\n",
    "df_incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932abc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using reasoning model: openai/gpt-oss-120b\n",
      "CoT Response :\n",
      "================================================================================\n",
      "1 | Gampaha | 08:00 AM | 4 | Water | Thirsty but safe on roof. Water level stable. | 5\n",
      "2 | Ja-Ela | 08:15 AM | 1 | Insulin | Diabetic, missed dose yesterday. Feeling faint. | 8\n",
      "3 | Ragama | 08:20 AM | 2 | Rescue | Water approaching neck level. Child is crying. | 8\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CoT auto-routes to reasoning model\n",
    "reasoning_model = pick_model('groq', 'cot')\n",
    "print(f'Using reasoning model: {reasoning_model}')\n",
    "\n",
    "client_reasoning = LLMClient('groq', reasoning_model)\n",
    "\n",
    "\n",
    "problem = incidents\n",
    "\n",
    "# Additional guidance \n",
    "instruction = \"\"\"You are a disaster logistics analyst.\n",
    "\n",
    "You must evaluate the following incident and assign a\n",
    "priority score using step-by-step reasoning internally.\n",
    "\n",
    "-----------------------------------\n",
    "SCORING RULES:\n",
    "- Base Score: 5\n",
    "- +2 if any person is younger than 5 or older than 60\n",
    "- +3 if Main Need is \"Rescue\" (immediate life threat)\n",
    "- +1 if Main Need is \"Insulin\" or urgent medicine\n",
    "- Maximum possible score: 10\n",
    "\n",
    "-----------------------------------\n",
    "INCIDENT DETAILS:\n",
    "Area: {area}\n",
    "People: {people}\n",
    "Ages: {ages}\n",
    "Main Need: {main_need}\n",
    "Message: \"{message}\"\n",
    "\n",
    "-----------------------------------\n",
    "IMPORTANT:\n",
    "- You MUST reason step-by-step internally\n",
    "- You MUST NOT show your reasoning\n",
    "- You MUST output ONLY the final score\n",
    "\n",
    "-----------------------------------\n",
    "OUTPUT FORMAT (STRICT):\n",
    "{row['id']} | {row['area']} | {row['time']} | {row['people']} | {row['main_need']} | {row['message']} | SCORE}\n",
    "\t\t\t\t\n",
    "\"\"\"\n",
    "\n",
    "prompt_text, spec = render(\n",
    "    'cot_reasoning.v1',\n",
    "    role='disaster logistics analyst',\n",
    "    problem=problem\n",
    ")\n",
    "\n",
    "# Combine problem with instruction \n",
    "full_prompt = f\"\"\"text: {prompt_text}\n",
    "\n",
    "instruction: {instruction}\"\"\"\n",
    "\n",
    "messages = [{'role': 'user', 'content': full_prompt}]\n",
    "response = client_reasoning.chat(messages, temperature=spec.temperature, max_tokens=spec.max_tokens)\n",
    "\n",
    "print('CoT Response :')\n",
    "print('=' * 80)\n",
    "print(response['text'])\n",
    "print('=' * 80)\n",
    "log_llm_call('groq', reasoning_model, 'cot', response['latency_ms'], response['usage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e514334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID | Area | Time | People | Main Need | Message | Priority Score\n",
      "1 | Gampaha | 08:00 AM | 4 | Water | Thirsty but safe on roof. Water level stable. | 5\n",
      "2 | Ja-Ela | 08:15 AM | 1 | Insulin | Diabetic, missed dose yesterday. Feeling faint. | 8\n",
      "3 | Ragama | 08:20 AM | 2 | Rescue | Water approaching neck level. Child is crying. | 8\n"
     ]
    }
   ],
   "source": [
    "incident_table = f\"ID | Area | Time | People | Main Need | Message | Priority Score\\n{response['text']}\"\n",
    "\n",
    "print(incident_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c5a0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToT Response (Multiple Solution Paths):\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Branch 1 – Greedy (Highest Score First)**  \n",
       "\n",
       "**Hypothesis** – By tackling the two incidents with the highest priority scores (8 pts each) before the lower‑scoring one (5 pts), we will maximise the “score saved” even if the travel distance grows.  \n",
       "\n",
       "**Steps**  \n",
       "\n",
       "1. **Start @ Ragama (08:00).**  \n",
       "2. **Go to Ja‑Ela** – 10 min travel → arrive 08:10 (before the 08:15 incident).  \n",
       "   *Serve ID 2 (score 8).*  \n",
       "3. **Return to Ragama** – 10 min travel → arrive 08:20 (exactly when ID 3 needs help).  \n",
       "   *Serve ID 3 (score 8).*  \n",
       "4. **Proceed to Gampaha** – Ragama → Ja‑Ela (10 min) + Ja‑Ela → Gampaha (40 min) = 50 min → arrive 09:10.  \n",
       "   *Serve ID 1 (score 5).*\n",
       "\n",
       "**Intermediate check** – All three incidents are eventually served; total travel = 10 + 10 + 50 = **70 min**.  \n",
       "\n",
       "**Result** – Total priority score saved = **8 + 8 + 5 = 21** points.  \n",
       "\n",
       "---\n",
       "\n",
       "**Branch 2 – Speed (Closest First)**  \n",
       "\n",
       "**Hypothesis** – Visiting the nearest locations first minimises dead‑head travel, allowing us to finish the whole mission faster while still rescuing everyone.  \n",
       "\n",
       "**Steps**  \n",
       "\n",
       "1. **Start @ Ragama (08:00).**  \n",
       "2. **Serve Ragama incident immediately** (no travel).  \n",
       "   *Serve ID 3 at 08:20 (score 8).*  \n",
       "3. **Go to Ja‑Ela** – 10 min travel → arrive 08:30 (15 min after the incident time, but still reachable).  \n",
       "   *Serve ID 2 (score 8).*  \n",
       "4. **Go to Gampaha** – 40 min travel → arrive 09:10.  \n",
       "   *Serve ID 1 (score 5).*\n",
       "\n",
       "**Intermediate check** – All incidents are covered; total travel = **0 + 10 + 40 = 50 min**.  \n",
       "\n",
       "**Result** – Total priority score saved = **21** points (same as Branch 1) with **20 min less travel**.\n",
       "\n",
       "---\n",
       "\n",
       "**Branch 3 – Logistics (Furthest First)**  \n",
       "\n",
       "**Hypothesis** – By heading to the farthest point first we eliminate the “return‑trip penalty” later; the longer leg is done only once.  \n",
       "\n",
       "**Steps**  \n",
       "\n",
       "1. **Start @ Ragama (08:00).**  \n",
       "2. **Travel to Gampaha** – Ragama → Ja‑Ela (10 min) + Ja‑Ela → Gampaha (40 min) = 50 min → arrive 08:50.  \n",
       "   *Serve ID 1 (score 5).*  \n",
       "3. **Backtrack to Ja‑Ela** – 40 min travel → arrive 09:30.  \n",
       "   *Serve ID 2 (score 8).*  \n",
       "4. **Return to Ragama** – 10 min travel → arrive 09:40.  \n",
       "   *Serve ID 3 (score 8).*\n",
       "\n",
       "**Intermediate check** – All incidents are served; total travel = **50 + 40 + 10 = 100 min**.  \n",
       "\n",
       "**Result** – Total priority score saved = **21** points, but with the longest overall travel time.\n",
       "\n",
       "---\n",
       "\n",
       "### Comparison\n",
       "\n",
       "| Branch | Order of Visits | Travel Time | Score Saved |\n",
       "|--------|----------------|------------|------------|\n",
       "| 1 – Greedy | Ja‑Ela → Ragama → Gampaha | 70 min | 21 |\n",
       "| 2 – Speed  | Ragama → Ja‑Ela → Gampaha | **50 min** | **21** |\n",
       "| 3 – Logistics | Gampaha → Ja‑Ela → Ragama | 100 min | 21 |\n",
       "\n",
       "All three routes ultimately rescue every victim, yielding the same total priority score (21 pts). The decisive factor is **overall travel time**.  \n",
       "\n",
       "---\n",
       "\n",
       "## FINAL DECISION  \n",
       "**Optimal Route:** **Branch 2 – Speed (Closest First)** → **Ragama → Ja‑Ela → Gampaha**  \n",
       "\n",
       "**Justification:**  \n",
       "- Saves the full 21 priority points (no loss of lives/needs).  \n",
       "- Minimises total travel to **50 minutes**, 20 minutes faster than the Greedy approach and 50 minutes faster than the Logistics approach.  \n",
       "- By handling the incident already at the boat’s location first, we avoid any unnecessary waiting and keep the mission as swift as possible, which is critical in disaster response.  \n",
       "\n",
       "**Answer:** Deploy the rescue boat to **Ragama (serve incident 3), then sail 10 min to Ja‑Ela (serve incident 2), then continue 40 min to Gampaha (serve incident 1)** – total travel 50 minutes, total priority score saved = 21."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "problem = f\"\"\"You have ONE rescue boat located at Ragama.\n",
    "\n",
    "Travel Time Constraints:\n",
    "- Ragama → Ja-Ela: 10 minutes\n",
    "- Ja-Ela → Gampaha: 40 minutes\n",
    "\n",
    "Each incident requires one stop.\n",
    "Assume unlimited capacity per stop.\n",
    "\n",
    "-----------------------------------\n",
    "INCIDENTS WITH PRIORITY SCORES:\n",
    "{incident_table}\n",
    "\n",
    "-----------------------------------\n",
    "STRATEGY BRANCHES TO EXPLORE:\n",
    "\n",
    "Branch 1 - Greedy (Highest Score First):\n",
    "Visit incidents in descending order of priority score.\n",
    "\n",
    "Branch 2 - Speed (Closest First):\n",
    "Visit the nearest locations first to minimize travel time.\n",
    "\n",
    "Branch 3 - Logistics (Furthest First):\n",
    "Visit the furthest locations first to reduce later delays.\n",
    "\n",
    "-----------------------------------\n",
    "GOAL:\n",
    "Maximize total priority score saved within the shortest\n",
    "overall travel time.\n",
    "\n",
    "-----------------------------------\n",
    "TASK:\n",
    "1. Evaluate each branch independently\n",
    "2. Compute total score saved and travel time\n",
    "3. Compare all branches\n",
    "4. Select the optimal route\n",
    "\n",
    "-----------------------------------\n",
    "OUTPUT FORMAT:\n",
    "\n",
    "Branch 1 Analysis:\n",
    "...\n",
    "\n",
    "Branch 2 Analysis:\n",
    "...\n",
    "\n",
    "Branch 3 Analysis:\n",
    "...\n",
    "\n",
    "FINAL DECISION:\n",
    "Optimal Route: ...\n",
    "Justification: ...\n",
    "\"\"\"\n",
    "\n",
    "prompt_text, spec = render(\n",
    "    'tot_reasoning.v1',\n",
    "    role='disaster logistics analyst',\n",
    "    problem=problem,\n",
    "    branches='3'\n",
    ")\n",
    "\n",
    "messages = [{'role': 'user', 'content': prompt_text}]\n",
    "response = client_reasoning.chat(messages, temperature=spec.temperature, max_tokens=spec.max_tokens)\n",
    "\n",
    "print('ToT Response (Multiple Solution Paths):')\n",
    "print('=' * 80)\n",
    "display(Markdown(response['text']))\n",
    "print('=' * 80)\n",
    "log_llm_call('groq', reasoning_model, 'tot', response['latency_ms'], response['usage'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sahas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
